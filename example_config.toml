[audio]
device = "default"
sample_rate = 16000
channels = 1

[whisper]
# Provider selection (defaults to auto-detection if not specified)
# Uncomment and set provider to explicitly choose:
# provider = "whisper-cpp"    # Local whisper.cpp (built during install)
# provider = "openai-cli"     # Local OpenAI Whisper CLI 
# provider = "openai-api"     # OpenAI API (requires api_key)

# Common settings
model = "base"              # Model size: tiny, base, small, medium, large-v3, large-v3-turbo
language = "en"             # Language code (en, es, fr, de, etc.)

# whisper.cpp settings (used when provider = "whisper-cpp")
# command_path = "/path/to/whisper-cli"  # Optional custom path
# model_path = "/path/to/model.bin"      # Optional custom model path

# OpenAI CLI settings (used when provider = "openai-cli")
# command_path = "/path/to/whisper"      # Optional custom path

# OpenAI API settings (used when provider = "openai-api")
# api_key = "sk-your-key"                # Required for API
# model = "whisper-1"                    # API model name
# api_endpoint = "https://api.openai.com/v1/audio/transcriptions"  # Optional

[ui]
indicator_position = "top-right"
indicator_size = 20
show_notifications = true
layer_shell_anchor = "top | right"
layer_shell_margin = 10
notification_color = "rgb(ff1744)"  # Hyprland notification color

[ui.waybar]
idle_text = "󰑊"                # Icon shown when idle (ready to record) - Nerd Font
recording_text = "󰻃"           # Icon shown when recording - Nerd Font
processing_text = "󰦖"          # Icon shown when processing - Nerd Font
idle_tooltip = "Press Super+R to record"
recording_tooltip = "Recording... Press Super+R to stop"
processing_tooltip = "Processing transcription..."

[wayland]
input_method = "wtype"
use_hyprland_ipc = true

[behavior]
auto_paste = true
preserve_clipboard = false
delete_audio_files = true
audio_feedback = true